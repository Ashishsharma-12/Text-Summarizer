{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox, ttk\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from pypdf import PdfReader\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummarizer:\n",
    "    def __init__(self):\n",
    "        # Initialize spaCy model\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"Error: Please install the spaCy model by running:\")\n",
    "            print(\"python -m spacy download en_core_web_sm\")\n",
    "            raise\n",
    "    \n",
    "    def summarize(self, text, percent=0.3):\n",
    "        \"\"\"\n",
    "        Generate a summary of the given text using TextRank algorithm\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to summarize\n",
    "            percent (float): Percentage of original text to include in summary (0.1 to 0.5)\n",
    "            \n",
    "        Returns:\n",
    "            str: The generated summary\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            return \"No text provided for summarization.\"\n",
    "            \n",
    "        # Make sure percent is between 0.1 and 0.5\n",
    "        percent = max(0.1, min(0.5, percent))\n",
    "        \n",
    "        return self.textrank_summary(text, percent)\n",
    "    \n",
    "    def textrank_summary(self, text, per):\n",
    "        \"\"\"Generate text summary using TextRank algorithm\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        sentences = list(doc.sents)\n",
    "        \n",
    "        if len(sentences) <= 1:\n",
    "            return text\n",
    "        \n",
    "        # Create sentence vectors using spaCy's word vectors\n",
    "        sentence_vectors = []\n",
    "        for sent in sentences:\n",
    "            # Skip sentences with no words with vectors\n",
    "            if not any(token.has_vector for token in sent):\n",
    "                sent_vec = np.zeros((len(sent), 96))  # Default embedding dimension\n",
    "            else:\n",
    "                words_with_vectors = [token.vector for token in sent if token.has_vector]\n",
    "                if not words_with_vectors:\n",
    "                    sent_vec = np.zeros(96)  # Default dimension\n",
    "                else:\n",
    "                    sent_vec = np.mean(words_with_vectors, axis=0)\n",
    "            sentence_vectors.append(sent_vec)\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "        \n",
    "        # Fill the similarity matrix\n",
    "        for i in range(len(sentences)):\n",
    "            for j in range(len(sentences)):\n",
    "                if i != j:\n",
    "                    # Make sure we don't divide by zero\n",
    "                    if np.linalg.norm(sentence_vectors[i]) * np.linalg.norm(sentence_vectors[j]) == 0:\n",
    "                        sim_mat[i][j] = 0\n",
    "                    else:\n",
    "                        sim_mat[i][j] = self._cosine_similarity(sentence_vectors[i], sentence_vectors[j])\n",
    "        \n",
    "        # Create networkx graph and add edges with weights\n",
    "        nx_graph = nx.from_numpy_array(sim_mat)\n",
    "        \n",
    "        # Apply PageRank algorithm\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "        \n",
    "        # Sort sentences by score and select top sentences\n",
    "        ranked_sentences = sorted(((scores[i], i, s) for i, s in enumerate(sentences)), reverse=True)\n",
    "        \n",
    "        # Calculate the number of sentences for the summary\n",
    "        summary_size = max(1, int(len(sentences) * per))\n",
    "        \n",
    "        # Get top N sentences and sort them by original position\n",
    "        top_sentences = sorted(ranked_sentences[:summary_size], key=lambda x: x[1])\n",
    "        \n",
    "        # Combine sentences into summary\n",
    "        summary = \" \".join([s.text for _, _, s in top_sentences])\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "        # Handle zero vectors\n",
    "        if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "            return 0\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file and return as a single string.\"\"\"\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text_content = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text.strip():\n",
    "            text_content.append(text.strip())\n",
    "    return \" \".join(text_content)\n",
    "\n",
    "def extract_text_from_docx(docx_file):\n",
    "    \"\"\"Extract text from a Word document and return as a single string.\"\"\"\n",
    "    doc = Document(docx_file)\n",
    "    text_content = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text.strip():\n",
    "            text_content.append(paragraph.text.strip())\n",
    "    return \" \".join(text_content)\n",
    "\n",
    "def extract_text(file):\n",
    "    \"\"\"Extract text from either PDF or Word document.\"\"\"\n",
    "    file_type = file.name.split('.')[-1].lower()\n",
    "    if file_type == 'pdf':\n",
    "        return extract_text_from_pdf(file)\n",
    "    elif file_type in ['docx', 'doc']:\n",
    "        return extract_text_from_docx(file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 03:57:56.368 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.371 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-03-25 03:57:56.372 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.373 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.374 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.375 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.375 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.376 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.433 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run d:\\Anaconda\\envs\\tensorflow\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-25 03:57:56.434 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.434 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-25 03:57:56.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if 'uploaded_file' not in st.session_state:\n",
    "        st.session_state.uploaded_file = None   \n",
    "    if 'summary' not in st.session_state:\n",
    "        st.session_state.summary = \"\"\n",
    "\n",
    "    st.title(\"Text Summarizer\")\n",
    "\n",
    "    with st.sidebar:\n",
    "        uploaded_file = st.file_uploader(\"Choose a file\", type=['pdf', 'docx', 'doc'])\n",
    "\n",
    "        if uploaded_file:\n",
    "            st.session_state.uploaded_file = uploaded_file\n",
    "        \n",
    "        summary_percent = st.slider(\"Summary Length (%)\", \n",
    "                                  min_value=10, \n",
    "                                  max_value=50, \n",
    "                                  value=30,\n",
    "                                  help=\"Select the percentage of original text to keep in summary\")\n",
    "        \n",
    "        if st.button(\"Generate Summary\"):\n",
    "            try:\n",
    "                if st.session_state.uploaded_file:\n",
    "                    with st.spinner(\"Extracting text and generating summary...\"):\n",
    "                        # Extract text from file\n",
    "                        text = extract_text(uploaded_file)\n",
    "                        if not text.strip():\n",
    "                            st.error(\"Could not extract text from the file. Please make sure it's a text-based file.\")\n",
    "                            st.stop()\n",
    "                        \n",
    "                        # Initialize summarizer and generate summary\n",
    "                        summarizer = TextSummarizer()\n",
    "                        st.session_state.summary = summarizer.summarize(text, summary_percent/100)\n",
    "                        st.success(\"Summary generated successfully!\")\n",
    "                else:\n",
    "                    st.warning(\"Please upload a file first.\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error processing file: {str(e)}\")\n",
    "\n",
    "    if st.session_state.summary:\n",
    "        st.subheader(\"Generated Summary\")\n",
    "        st.markdown(f\"{st.session_state.summary}\")\n",
    "        \n",
    "        # Display original text length vs summary length\n",
    "        original_words = len(text.split()) if 'text' in locals() else 0\n",
    "        summary_words = len(st.session_state.summary.split())\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.metric(\"Original Text Length\", f\"{original_words} words\")\n",
    "        with col2:\n",
    "            st.metric(\"Summary Length\", f\"{summary_words} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Streamlit requires raw Python (.py) files, but the provided file has no extension.\n",
      "For more information, please see https://docs.streamlit.io\n"
     ]
    }
   ],
   "source": [
    "!npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run /content/app.py &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
